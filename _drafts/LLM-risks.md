---
layout: post
title: Risks of LLMs
---


1. Giving sensitive information to the LLM, which logs your data
	eg. if a teenager uses the LLM as a therapeutic buddy and what they reveal to the LLM eventually becomes public information
2. Leaking sensitive information that is legally private (e.g., the data was unknowingly or unlawfully leaked so that reproduction of that data is an accomplice to a crime -- see Pentagon papers)

3. Losing skills because people supplant their work with the LLM. Rather than using it as a calculator in which people understand how and when they need to use it, people would "cheat" on their assignments by getting something else to do it for them.
	eg students cheating on their assignments and losing the ability to complete it themselves
4. Moral agency -- people supplant their own agency by completely depending on the LLM to make their decisions for them.
	eg. a person asking the LLM to write their essay for them, and not checking what the LLM wrote thereafter
	eg. the movie Eagle Eye

5. Identity propoganda -- responding to answers with a particular worldview 
	(e.g., identity politics and either sugggesting that their are two genders, are infinite genders, or what a legal number of genders are)
5b. Representation bias -- whose avatar the LLM / virtual agent represents, or the type or phrasing of language that the LLM responds with
5c. Self-censorship -- the LLM may choose not to respond to a question so that it doens't take a particular political position on a sensitive political issue

6. Connotation ambiguity -- the LLM may respond with language that a human may not interpret well
	eg. "Let's eat grandma!"
6b. Connotation bias -- the LLM is trained with a particular worldview
	eg. connoting "secretary" with "woman" more highly than "man"

7. Pejorative responses -- responding with only limited amount of information to questions, such as to children
	eg. a company's [virtual assistant](https://www.ibm.com/topics/virtual-agent){:target="_blank"} may not provide information about who's PACs the company donates to
	eg. it doesn't provide significant information about, say, how a government spies on its own citizens

8. Legal entitlement -- a company whose [virtual assistant](https://www.ibm.com/topics/virtual-agent){:target="_blank"} makes a declaration in which the corporate sponsor is legally liable (e.g., encouraging someone to commit a crime).

9. Logical and interpretation inconsistency -- the LLM's logic is not consistent and it may not interpret information it is given correctly


